{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29c811b-11b8-437b-8258-5642e1821cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1615779f-a896-4d94-985c-b7bc0092ee96",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/respiratory_sound_database'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/respiratory_sound_database\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/respiratory_sound_database'"
     ]
    }
   ],
   "source": [
    "os.listdir('../input/respiratory_sound_database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1cfee0b-5a29-45ea-8444-50b4c141b4ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/demographic_info.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_no_diagnosis \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/demographic_info.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, names \u001b[38;5;241m=\u001b[39m \n\u001b[0;32m      2\u001b[0m                  [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient number\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdult BMI (kg/m2)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChild Weight (kg)\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChild Height (cm)\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      3\u001b[0m                  delimiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m diagnosis \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient number\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/demographic_info.txt'"
     ]
    }
   ],
   "source": [
    "df_no_diagnosis = pd.read_csv('../input/demographic_info.txt', names = ['Patient number', 'Age', 'Sex' , 'Adult BMI (kg/m2)', 'Child Weight (kg)' , 'Child Height (cm)'], delimiter = ' ')\n",
    "\n",
    "diagnosis = pd.read_csv('../input/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv', names = ['Patient number', 'Diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7f3fad-36c7-4c29-ab24-db702a468074",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_no_diagnosis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m  df_no_diagnosis\u001b[38;5;241m.\u001b[39mjoin(diagnosis\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient number\u001b[39m\u001b[38;5;124m'\u001b[39m), on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient number\u001b[39m\u001b[38;5;124m'\u001b[39m, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_no_diagnosis' is not defined"
     ]
    }
   ],
   "source": [
    "df =  df_no_diagnosis.join(diagnosis.set_index('Patient number'), on = 'Patient number', how = 'left')\n",
    "df['Diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ccf816-783e-4196-9615-f965fcd7eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../input/respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files/'\n",
    "filenames = [s.split('.')[0] for s in os.listdir(path = root) if '.txt' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e87be-77f7-4eef-adb8-27b1d7e83aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Annotation_Data(file_name, root):\n",
    "    tokens = file_name.split('_')\n",
    "    recording_info = pd.DataFrame(data = [tokens], columns = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment'])\n",
    "    recording_annotations = pd.read_csv(os.path.join(root, file_name + '.txt'), names = ['Start', 'End', 'Crackles', 'Wheezes'], delimiter= '\\t')\n",
    "    return (recording_info, recording_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9471c4-998a-48e1-aec3-2a712b93feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_list = []\n",
    "rec_annotations = []\n",
    "rec_annotations_dict = {}\n",
    "for s in filenames:\n",
    "    (i,a) = Extract_Annotation_Data(s, root)\n",
    "    i_list.append(i)\n",
    "    rec_annotations.append(a)\n",
    "    rec_annotations_dict[s] = a\n",
    "recording_info = pd.concat(i_list, axis = 0)\n",
    "recording_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9625d-dee2-43d8-8853-70e10fae971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_label_list = []\n",
    "crack_list = []\n",
    "wheeze_list = []\n",
    "both_sym_list = []\n",
    "filename_list = []\n",
    "for f in filenames:\n",
    "    d = rec_annotations_dict[f]\n",
    "    no_labels = len(d[(d['Crackles'] == 0) & (d['Wheezes'] == 0)].index)\n",
    "    n_crackles = len(d[(d['Crackles'] == 1) & (d['Wheezes'] == 0)].index)\n",
    "    n_wheezes = len(d[(d['Crackles'] == 0) & (d['Wheezes'] == 1)].index)\n",
    "    both_sym = len(d[(d['Crackles'] == 1) & (d['Wheezes'] == 1)].index)\n",
    "    no_label_list.append(no_labels)\n",
    "    crack_list.append(n_crackles)\n",
    "    wheeze_list.append(n_wheezes)\n",
    "    both_sym_list.append(both_sym)\n",
    "    filename_list.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e10ce-8b00-4cbe-a2cd-1c22a1c62e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_label_df = pd.DataFrame(data = {'filename':filename_list, 'no label':no_label_list, 'crackles only':crack_list, 'wheezes only':wheeze_list, 'crackles and wheezees':both_sym_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf96f9b-3277-4148-a0ce-70639d8fe4a3",
   "metadata": {},
   "source": [
    "### Distribution of data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a293faa-b852-480a-8487-ef12ffb99ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_labels = file_label_df[(file_label_df['crackles only'] != 0) | (file_label_df['wheezes only'] != 0) | (file_label_df['crackles and wheezees'] != 0)]\n",
    "file_label_df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291dcc0-08d9-4e6f-8a62-7aaf6fae6656",
   "metadata": {},
   "source": [
    "### Utility functions for reading .wav files (especially pesky 24bit .wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce1240-045c-4f1c-9ee9-11276cff8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import math\n",
    "import scipy.io.wavfile as wf\n",
    "#wave file reader\n",
    "\n",
    "#Will resample all files to the target sample rate and produce a 32bit float array\n",
    "def read_wav_file(str_filename, target_rate):\n",
    "    wav = wave.open(str_filename, mode = 'r')\n",
    "    (sample_rate, data) = extract2FloatArr(wav,str_filename)\n",
    "    \n",
    "    if (sample_rate != target_rate):\n",
    "        ( _ , data) = resample(sample_rate, data, target_rate)\n",
    "        \n",
    "    wav.close()\n",
    "    return (target_rate, data.astype(np.float32))\n",
    "\n",
    "def resample(current_rate, data, target_rate):\n",
    "    x_original = np.linspace(0,100,len(data))\n",
    "    x_resampled = np.linspace(0,100, int(len(data) * (target_rate / current_rate)))\n",
    "    resampled = np.interp(x_resampled, x_original, data)\n",
    "    return (target_rate, resampled.astype(np.float32))\n",
    "\n",
    "# -> (sample_rate, data)\n",
    "def extract2FloatArr(lp_wave, str_filename):\n",
    "    (bps, channels) = bitrate_channels(lp_wave)\n",
    "    \n",
    "    if bps in [1,2,4]:\n",
    "        (rate, data) = wf.read(str_filename)\n",
    "        divisor_dict = {1:255, 2:32768}\n",
    "        if bps in [1,2]:\n",
    "            divisor = divisor_dict[bps]\n",
    "            data = np.divide(data, float(divisor)) #clamp to [0.0,1.0]        \n",
    "        return (rate, data)\n",
    "    \n",
    "    elif bps == 3: \n",
    "        #24bpp wave\n",
    "        return read24bitwave(lp_wave)\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Unrecognized wave format: {} bytes per sample'.format(bps))\n",
    "\n",
    "#Note: This function truncates the 24 bit samples to 16 bits of precision\n",
    "#Reads a wave object returned by the wave.read() method\n",
    "#Returns the sample rate, as well as the audio in the form of a 32 bit float numpy array\n",
    "#(sample_rate:float, audio_data: float[])\n",
    "def read24bitwave(lp_wave):\n",
    "    nFrames = lp_wave.getnframes()\n",
    "    buf = lp_wave.readframes(nFrames)\n",
    "    reshaped = np.frombuffer(buf, np.int8).reshape(nFrames,-1)\n",
    "    short_output = np.empty((nFrames, 2), dtype = np.int8)\n",
    "    short_output[:,:] = reshaped[:, -2:]\n",
    "    short_output = short_output.view(np.int16)\n",
    "    return (lp_wave.getframerate(), np.divide(short_output, 32768).reshape(-1))  #return numpy array to save memory via array slicing\n",
    "\n",
    "def bitrate_channels(lp_wave):\n",
    "    bps = (lp_wave.getsampwidth() / lp_wave.getnchannels()) #bytes per sample\n",
    "    return (bps, lp_wave.getnchannels())\n",
    "\n",
    "def slice_data(start, end, raw_data,  sample_rate):\n",
    "    max_ind = len(raw_data) \n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind: end_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14773a-6d4d-4850-b477-e869f5ceaa40",
   "metadata": {},
   "source": [
    "### Distribution of respiratory cycle lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7bfe2c-1353-4059-a782-b5721e8002c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_list = []\n",
    "for i in range(len(rec_annotations)):\n",
    "    current = rec_annotations[i]\n",
    "    duration = current['End'] - current['Start']\n",
    "    duration_list.extend(duration)\n",
    "\n",
    "duration_list = np.array(duration_list)\n",
    "plt.hist(duration_list, bins = 50)\n",
    "print('longest cycle:{}'.format(max(duration_list)))\n",
    "print('shortest cycle:{}'.format(min(duration_list)))\n",
    "threshold = 5\n",
    "print('Fraction of samples less than {} seconds:{}'.format(threshold, np.sum(duration_list < threshold)/len(duration_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922ff88-7c7c-4bdb-8413-81126ca24c9e",
   "metadata": {},
   "source": [
    "### Mel spectrogram implementation (With VTLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969ec88-4139-4741-a80c-ed8e437e8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "#vtlp_params = (alpha, f_high) \n",
    "def sample2MelSpectrum(cycle_info, sample_rate, n_filters, vtlp_params):\n",
    "    n_rows = 175 # 7500 cutoff\n",
    "    n_window = 512 #~25 ms window\n",
    "    (f, t, Sxx) = scipy.signal.spectrogram(cycle_info[0],fs = sample_rate, nfft= n_window, nperseg=n_window)\n",
    "    Sxx = Sxx[:n_rows,:].astype(np.float32) #sift out coefficients above 7500hz, Sxx has 196 columns\n",
    "    mel_log = FFT2MelSpectrogram(f[:n_rows], Sxx, sample_rate, n_filters, vtlp_params)[1]\n",
    "    mel_min = np.min(mel_log)\n",
    "    mel_max = np.max(mel_log)\n",
    "    diff = mel_max - mel_min\n",
    "    norm_mel_log = (mel_log - mel_min) / diff if (diff > 0) else np.zeros(shape = (n_filters,Sxx.shape[1]))\n",
    "    if (diff == 0):\n",
    "        print('Error: sample data is completely empty')\n",
    "    labels = [cycle_info[1], cycle_info[2]] #crackles, wheezes flags\n",
    "    return (np.reshape(norm_mel_log, (n_filters,Sxx.shape[1],1)).astype(np.float32), label2onehot(labels)) \n",
    "\n",
    "def Freq2Mel(freq):\n",
    "    return 1125 * np.log(1 + freq / 700)\n",
    "\n",
    "def Mel2Freq(mel):\n",
    "    exponents = mel / 1125\n",
    "    return 700 * (np.exp(exponents) - 1)\n",
    "\n",
    "#Tased on Jaitly & Hinton(2013)\n",
    "#Takes an array of the original mel spaced frequencies and returns a warped version of them\n",
    "def VTLP_shift(mel_freq, alpha, f_high, sample_rate):\n",
    "    nyquist_f = sample_rate / 2\n",
    "    warp_factor = min(alpha, 1)\n",
    "    threshold_freq = f_high * warp_factor / alpha\n",
    "    lower = mel_freq * alpha\n",
    "    higher = nyquist_f - (nyquist_f - mel_freq) * ((nyquist_f - f_high * warp_factor) / (nyquist_f - f_high * (warp_factor / alpha)))\n",
    "    \n",
    "    warped_mel = np.where(mel_freq <= threshold_freq, lower, higher)\n",
    "    return warped_mel.astype(np.float32)\n",
    "\n",
    "#mel_space_freq: the mel frequencies (HZ) of the filter banks, in addition to the two maximum and minimum frequency values\n",
    "#fft_bin_frequencies: the bin freqencies of the FFT output\n",
    "#Generates a 2d numpy array, with each row containing each filter bank\n",
    "def GenerateMelFilterBanks(mel_space_freq, fft_bin_frequencies):\n",
    "    n_filters = len(mel_space_freq) - 2\n",
    "    coeff = []\n",
    "    #Triangular filter windows\n",
    "    #ripped from http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "    for mel_index in range(n_filters):\n",
    "        m = int(mel_index + 1)\n",
    "        filter_bank = []\n",
    "        for f in fft_bin_frequencies:\n",
    "            if(f < mel_space_freq[m-1]):\n",
    "                hm = 0\n",
    "            elif(f < mel_space_freq[m]):\n",
    "                hm = (f - mel_space_freq[m-1]) / (mel_space_freq[m] - mel_space_freq[m-1])\n",
    "            elif(f < mel_space_freq[m + 1]):\n",
    "                hm = (mel_space_freq[m+1] - f) / (mel_space_freq[m + 1] - mel_space_freq[m])\n",
    "            else:\n",
    "                hm = 0\n",
    "            filter_bank.append(hm)\n",
    "        coeff.append(filter_bank)\n",
    "    return np.array(coeff, dtype = np.float32)\n",
    "\n",
    "#Transform spectrogram into mel spectrogram -> (frequencies, spectrum)\n",
    "#vtlp_params = (alpha, f_high), vtlp will not be applied if set to None\n",
    "def FFT2MelSpectrogram(f, Sxx, sample_rate, n_filterbanks, vtlp_params = None):\n",
    "    (max_mel, min_mel)  = (Freq2Mel(max(f)), Freq2Mel(min(f)))\n",
    "    mel_bins = np.linspace(min_mel, max_mel, num = (n_filterbanks + 2))\n",
    "    #Convert mel_bins to corresponding frequencies in hz\n",
    "    mel_freq = Mel2Freq(mel_bins)\n",
    "    \n",
    "    if(vtlp_params is None):\n",
    "        filter_banks = GenerateMelFilterBanks(mel_freq, f)\n",
    "    else:\n",
    "        #Apply VTLP\n",
    "        (alpha, f_high) = vtlp_params\n",
    "        warped_mel = VTLP_shift(mel_freq, alpha, f_high, sample_rate)\n",
    "        filter_banks = GenerateMelFilterBanks(warped_mel, f)\n",
    "        \n",
    "    mel_spectrum = np.matmul(filter_banks, Sxx)\n",
    "    return (mel_freq[1:-1], np.log10(mel_spectrum  + float(10e-12)))\n",
    "\n",
    "#labels proved too difficult to train (model keep convergining to statistical mean)\n",
    "#Flattened to onehot labels since the number of combinations is very low\n",
    "def label2onehot(c_w_flags):\n",
    "    c = c_w_flags[0]\n",
    "    w = c_w_flags[1]\n",
    "    if((c == False) & (w == False)):\n",
    "        return [1,0,0,0]\n",
    "    elif((c == True) & (w == False)):\n",
    "        return [0,1,0,0]\n",
    "    elif((c == False) & (w == True)):\n",
    "        return [0,0,1,0]\n",
    "    else:\n",
    "        return [0,0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e189c-ab42-4e34-adc3-21892937134f",
   "metadata": {},
   "source": [
    "### Data preparation utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b33984-4200-4205-be18-cf6b9c758f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to split each individual sound file into separate sound clips containing one respiratory cycle each\n",
    "#output: [filename, (sample_data:np.array, start:float, end:float, crackles:bool(float), wheezes:bool(float)) (...) ]\n",
    "def get_sound_samples(recording_annotations, file_name, root, sample_rate):\n",
    "    sample_data = [file_name]\n",
    "    (rate, data) = read_wav_file(os.path.join(root, file_name + '.wav'), sample_rate)\n",
    "    \n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        crackles = row['Crackles']\n",
    "        wheezes = row['Wheezes']\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start,end,crackles,wheezes))\n",
    "    return sample_data\n",
    "\n",
    "#Fits each respiratory cycle into a fixed length audio clip, splits may be performed and zero padding is added if necessary\n",
    "#original:(arr,c,w) -> output:[(arr,c,w),(arr,c,w)]\n",
    "def split_and_pad(original, desiredLength, sampleRate):\n",
    "    output_buffer_length = int(desiredLength * sampleRate)\n",
    "    soundclip = original[0]\n",
    "    n_samples = len(soundclip)\n",
    "    total_length = n_samples / sampleRate #length of cycle in seconds\n",
    "    n_slices = int(math.ceil(total_length / desiredLength)) #get the minimum number of slices needed\n",
    "    samples_per_slice = n_samples // n_slices\n",
    "    src_start = 0 #Staring index of the samples to copy from the original buffer\n",
    "    output = [] #Holds the resultant slices\n",
    "    for i in range(n_slices):\n",
    "        src_end = min(src_start + samples_per_slice, n_samples)\n",
    "        length = src_end - src_start\n",
    "        copy = generate_padded_samples(soundclip[src_start:src_end], output_buffer_length)\n",
    "        output.append((copy, original[1], original[2]))\n",
    "        src_start += length\n",
    "    return output\n",
    "\n",
    "def generate_padded_samples(source, output_length):\n",
    "    copy = np.zeros(output_length, dtype = np.float32)\n",
    "    src_length = len(source)\n",
    "    frac = src_length / output_length\n",
    "    if(frac < 0.5):\n",
    "        #tile forward sounds to fill empty space\n",
    "        cursor = 0\n",
    "        while(cursor + src_length) < output_length:\n",
    "            copy[cursor:(cursor + src_length)] = source[:]\n",
    "            cursor += src_length\n",
    "    else:\n",
    "        copy[:src_length] = source[:]\n",
    "    #\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb768a-b423-47f7-ac23-52d79ab5b50f",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "- Two basic forms employed : audio stretching (speeding up or down) as well as Vocal Tract Length perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6ff06-73e5-4020-9c82-f5eba067abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a copy of each time slice, but stretches or contracts it by a random amount\n",
    "def gen_time_stretch(original, sample_rate, max_percent_change):\n",
    "    stretch_amount = 1 + np.random.uniform(-1,1) * (max_percent_change / 100)\n",
    "    (_, stretched) = resample(sample_rate, original, int(sample_rate * stretch_amount)) \n",
    "    return stretched\n",
    "\n",
    "#Same as above, but applies it to a list of samples\n",
    "def augment_list(audio_with_labels, sample_rate, percent_change, n_repeats):\n",
    "    augmented_samples = []\n",
    "    for i in range(n_repeats):\n",
    "        addition = [(gen_time_stretch(t[0], sample_rate, percent_change), t[1], t[2] ) for t in audio_with_labels]\n",
    "        augmented_samples.extend(addition)\n",
    "    return augmented_samples\n",
    "\n",
    "#Takes a list of respiratory cycles, and splits and pads each cycle into fixed length buffers (determined by desiredLength(seconds))\n",
    "#Then takes the split and padded sample and transforms it into a mel spectrogram\n",
    "#VTLP_alpha_range = [Lower, Upper] (Bounds of random selection range), \n",
    "#VTLP_high_freq_range = [Lower, Upper] (-)\n",
    "#output:[(arr:float[],c:float_bool,w:float_bool),(arr,c,w)]\n",
    "def split_and_pad_and_apply_mel_spect(original, desiredLength, sampleRate, VTLP_alpha_range = None, VTLP_high_freq_range = None, n_repeats = 1):\n",
    "    output = []\n",
    "    for i in range(n_repeats):\n",
    "        for d in original:\n",
    "            lst_result = split_and_pad(d, desiredLength, sampleRate) #Time domain\n",
    "            if( (VTLP_alpha_range is None) | (VTLP_high_freq_range is None) ):\n",
    "                #Do not apply VTLP\n",
    "                VTLP_params = None\n",
    "            else:\n",
    "                #Randomly generate VLTP parameters\n",
    "                alpha = np.random.uniform(VTLP_alpha_range[0], VTLP_alpha_range[1])\n",
    "                high_freq = np.random.uniform(VTLP_high_freq_range[0], VTLP_high_freq_range[1])\n",
    "                VTLP_params = (alpha, high_freq)\n",
    "            freq_result = [sample2MelSpectrum(d, sampleRate, 50, VTLP_params) for d in lst_result] #Freq domain\n",
    "            output.extend(freq_result)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e68794-9617-4bfd-870b-7e523e17d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_file = filenames[11]\n",
    "lp_test = get_sound_samples(rec_annotations_dict[str_file], str_file, root, 22000)\n",
    "lp_cycles = [(d[0], d[3], d[4]) for d in lp_test[1:]]\n",
    "soundclip = lp_cycles[1][0]\n",
    "\n",
    "n_window = 512\n",
    "sample_rate = 22000\n",
    "(f, t, Sxx) = scipy.signal.spectrogram(soundclip, fs = 22000, nfft= n_window, nperseg=n_window)\n",
    "print(sum(f < 7000))\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1,2,1)\n",
    "mel_banks = FFT2MelSpectrogram(f[:175], Sxx[:175,:], sample_rate, 50)[1]\n",
    "plt.imshow(mel_banks, aspect = 1)\n",
    "plt.title('No VTLP')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "mel_banks = FFT2MelSpectrogram(f[:175], Sxx[:175,:], sample_rate, 50, vtlp_params = (0.9,3500))[1]\n",
    "plt.imshow(mel_banks, aspect = 1)\n",
    "plt.title('With VTLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb1ce8-cdee-4f6a-93d5-235226f867dc",
   "metadata": {},
   "source": [
    "### Utility used to import all training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8b200-3c5d-4758-a9a2-f80f84007ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def extract_all_training_samples(filenames, annotation_dict, root, target_rate, desired_length, train_test_ratio = 0.2):\n",
    "    cycle_list = []\n",
    "    for file in filenames:\n",
    "        data = get_sound_samples(annotation_dict[file], file, root, target_rate)\n",
    "        cycles_with_labels = [(d[0], d[3], d[4]) for d in data[1:]]\n",
    "        cycle_list.extend(cycles_with_labels)\n",
    "    \n",
    "    #Sort into respective classes\n",
    "    no_labels = [c for c in cycle_list if ((c[1] == 0) & (c[2] == 0))]\n",
    "    c_only = [c for c in cycle_list if ((c[1] == 1) & (c[2] == 0))] \n",
    "    w_only = [c for c in cycle_list if ((c[1] == 0) & (c[2] == 1))]\n",
    "    c_w = [c for c in cycle_list if ((c[1] == 1) & (c[2] == 1))]\n",
    "    \n",
    "    #Count of labels across all cycles, actual recording time also follows similar ratios\n",
    "    #none:3642\n",
    "    #crackles:1864 \n",
    "    #wheezes:886\n",
    "    #both:506\n",
    "    none_train, none_test = train_test_split(no_labels, test_size = train_test_ratio)\n",
    "    c_train, c_test  = train_test_split(c_only, test_size = train_test_ratio)\n",
    "    w_train, w_test  = train_test_split(w_only, test_size = train_test_ratio)\n",
    "    c_w_train, c_w_test  = train_test_split(c_w, test_size = train_test_ratio)\n",
    "\n",
    "    Training section (Data augmentation procedures)\n",
    "    #Augment w_only and c_w groups to match the size of c_only\n",
    "    #no_labels will be artifically reduced in the pipeline  later\n",
    "    w_stretch = w_train + augment_list(w_train, target_rate, 10 , 1) #\n",
    "    c_w_stretch = c_w_train + augment_list(c_w_train , target_rate, 10 , 1) \n",
    "    \n",
    "    #Split up cycles into sound clips with fixed lengths so they can be fed into a CNN\n",
    "    vtlp_alpha = [0.9,1.1]\n",
    "    vtlp_upper_freq = [3200,3800]\n",
    "    \n",
    "    train_none  = (split_and_pad_and_apply_mel_spect(none_train, desired_length, target_rate) +\n",
    "                   split_and_pad_and_apply_mel_spect(none_train, desired_length, target_rate, vtlp_alpha))\n",
    "    \n",
    "    train_c = (split_and_pad_and_apply_mel_spect(c_train, desired_length, target_rate) + \n",
    "               split_and_pad_and_apply_mel_spect(c_train, desired_length, target_rate, vtlp_alpha, vtlp_upper_freq, n_repeats = 3) ) #original samples + VTLP\n",
    "    \n",
    "    train_w = (split_and_pad_and_apply_mel_spect(w_stretch, desired_length, target_rate) + \n",
    "               split_and_pad_and_apply_mel_spect(w_stretch , desired_length, target_rate, vtlp_alpha , vtlp_upper_freq, n_repeats = 4)) #(original samples + time stretch) + VTLP\n",
    "    train_c_w = (split_and_pad_and_apply_mel_spect(c_w_stretch, desired_length, target_rate) + \n",
    "                 split_and_pad_and_apply_mel_spect(c_w_stretch, desired_length, target_rate, vtlp_alpha , vtlp_upper_freq, n_repeats = 7)) #(original samples + time stretch * 2) + VTLP\n",
    "    \n",
    "    train_dict = {'none':train_none,'crackles':train_c,'wheezes':train_w, 'both':train_c_w}\n",
    "    \n",
    "    #test section \n",
    "    test_none  = split_and_pad_and_apply_mel_spect(none_test, desired_length, target_rate)\n",
    "    test_c = split_and_pad_and_apply_mel_spect(c_test, desired_length, target_rate)\n",
    "    test_w = split_and_pad_and_apply_mel_spect(w_test, desired_length, target_rate)\n",
    "    test_c_w = split_and_pad_and_apply_mel_spect(c_w_test, desired_length, target_rate)\n",
    "    \n",
    "    test_dict = {'none':test_none,'crackles':test_c,'wheezes':test_w, 'both':test_c_w}\n",
    "    \n",
    "    return [train_dict, test_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91314a59-911a-40a8-8f9f-1873e5a41e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sample_rate = 22000 \n",
    "sample_length_seconds = 5\n",
    "sample_dict = extract_all_training_samples(filenames, rec_annotations_dict, root, target_sample_rate, sample_length_seconds) #sample rate lowered to meet memory constraints\n",
    "training_clips = sample_dict[0]\n",
    "test_clips = sample_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff511f4a-e797-4bb7-8af4-b3aa6f951a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_count(src_dict):\n",
    "    print('none:{}\\ncrackles:{}\\nwheezes:{}\\nboth:{}'.format(len(src_dict['none']), len(src_dict['crackles']), len(src_dict['wheezes']), len(src_dict['both'])))\n",
    "\n",
    "print('Samples Available')\n",
    "print('[Training set]')\n",
    "print_sample_count(training_clips)\n",
    "print('')\n",
    "print('[Test set]')\n",
    "print_sample_count(test_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea90e3d-6908-418a-a4f7-2ea117b3c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of tiled sound samples\n",
    "sample_height = training_clips['none'][0][0].shape[0]\n",
    "sample_width = training_clips['none'][0][0].shape[1]\n",
    "ind = 1\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(4,1,1)\n",
    "plt.imshow(training_clips['none'][ind][0].reshape(sample_height, sample_width))\n",
    "plt.title('None')\n",
    "plt.subplot(4,1,2)\n",
    "plt.imshow(training_clips['crackles'][ind][0].reshape(sample_height, sample_width))\n",
    "plt.title('Crackles')\n",
    "plt.subplot(4,1,3)\n",
    "plt.imshow(training_clips['wheezes'][ind][0].reshape(sample_height, sample_width))\n",
    "plt.title('Wheezes')\n",
    "plt.subplot(4,1,4)\n",
    "plt.imshow(training_clips['both'][ind][0].reshape(sample_height, sample_width))\n",
    "plt.title('Both')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b1c40-164a-41c7-b1fd-749e9f873834",
   "metadata": {},
   "source": [
    "### Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163ec3f-6981-49c2-858e-c84a7de63dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "#Interleaved sampling between classes\n",
    "#Used to ensure a balance of classes for the training set\n",
    "class data_generator():\n",
    "    #sound_clips = [[none],[crackles],[wheezes],[both]]\n",
    "    #strides: How far the sampling index for each category is advanced for each step\n",
    "    def __init__(self, sound_clips, strides):\n",
    "        self.clips = sound_clips\n",
    "        self.strides = strides\n",
    "        self.lengths = [len(arr) for arr in sound_clips]\n",
    "    \n",
    "    def n_available_samples(self):\n",
    "        return int(min(np.divide(self.lengths, self.strides))) * 4\n",
    "    \n",
    "    def generate_keras(self, batch_size):\n",
    "        cursor = [0,0,0,0]\n",
    "        while True:\n",
    "            i = 0\n",
    "            X,y = [],[]\n",
    "            for c in range(batch_size):\n",
    "                cat_length = self.lengths[i]\n",
    "                cat_clips = self.clips[i]\n",
    "                cat_stride = self.strides[i]\n",
    "                cat_advance = np.random.randint(low= 1,high = cat_stride + 1)\n",
    "                clip = cat_clips[(cursor[i] + cat_advance) % cat_length]\n",
    "                cursor[i] = (cursor[i] + self.strides[i]) % cat_length #advance cursor\n",
    "                s = (self.rollFFT(clip))\n",
    "                X.append(s[0])\n",
    "                y.append(s[1])\n",
    "                i = (i + 1) % 4 # go to next class\n",
    "            yield (np.reshape(X, (batch_size, sample_height, sample_width, 1)),\n",
    "                   np.reshape(y,(batch_size,4)))\n",
    "\n",
    "    #Transpose and wrap each array along the time axis\n",
    "    def rollFFT(self, fft_info):\n",
    "        fft = fft_info[0]\n",
    "        n_col = fft.shape[1]\n",
    "        pivot = np.random.randint(n_col)\n",
    "        return ((np.roll(fft, pivot, axis = 1)), fft_info[1])\n",
    "\n",
    "#Used for validation set\n",
    "class feed_all():\n",
    "    #sound_clips = [[none],[crackles],[wheezes],[both]]\n",
    "    #strides: How far the sampling index for each category is advanced for each step\n",
    "    def __init__(self, sound_clips, roll = True):\n",
    "        merged = []\n",
    "        for arr in sound_clips:\n",
    "            merged.extend(arr)\n",
    "        np.random.shuffle(merged)\n",
    "        self.clips = merged\n",
    "        self.nclips = len(merged)\n",
    "        self.roll = roll\n",
    "    \n",
    "    def n_available_samples(self):\n",
    "        return len(self.clips)\n",
    "\n",
    "    def generate_keras(self, batch_size):\n",
    "        i = 0\n",
    "        while True:\n",
    "            X,y = [],[]\n",
    "            for b in range(batch_size):\n",
    "                clip = self.clips[i]\n",
    "                i = (i + 1) % self.nclips\n",
    "                if(self.roll):\n",
    "                    s = (self.rollFFT(clip))\n",
    "                    X.append(s[0])\n",
    "                    y.append(s[1])\n",
    "                else:\n",
    "                    X.append(clip[0])\n",
    "                    y.append(clip[1])\n",
    "                    \n",
    "            yield (np.reshape(X, (batch_size,sample_height, sample_width,1)),\n",
    "                   np.reshape(y,(batch_size, 4)))\n",
    "\n",
    "    \n",
    "            #Transpose and wrap each array along the time axis\n",
    "    def rollFFT(self, fft_info):\n",
    "        fft = fft_info[0]\n",
    "        n_col = fft.shape[1]\n",
    "        pivot = np.random.randint(n_col)\n",
    "        return ((np.roll(fft, pivot, axis = 1)), fft_info[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19dd3c5-8578-4c6f-8342-24760dd99be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[none_train, c_train, w_train, c_w_train] = [training_clips['none'], training_clips['crackles'], training_clips['wheezes'], training_clips['both']]\n",
    "[none_test, c_test, w_test,c_w_test] =  [test_clips['none'], test_clips['crackles'], test_clips['wheezes'], test_clips['both']]\n",
    "\n",
    "np.random.shuffle(none_train)\n",
    "np.random.shuffle(c_train)\n",
    "np.random.shuffle(w_train)\n",
    "np.random.shuffle(c_w_train)\n",
    "\n",
    "#Data pipeline objects\n",
    "train_gen = data_generator([none_train, c_train, w_train, c_w_train], [1,1,1,1])\n",
    "test_gen = feed_all([none_test, c_test, w_test,c_w_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0884d6c-d009-4cb2-b120-d9600132c237",
   "metadata": {},
   "source": [
    "### CNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ab715-a9f4-407a-a390-2a525050a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29b666-fc63-41ef-a3fb-106320a71fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras implementation\n",
    "from keras import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Dense, Activation, Dropout, MaxPool2D, Flatten, LeakyReLU\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, [7,11], strides = [2,2], padding = 'SAME', input_shape = (sample_height, sample_width, 1)))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(MaxPool2D(padding = 'SAME'))\n",
    "\n",
    "model.add(Conv2D(256, [5,5], padding = 'SAME'))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(MaxPool2D(padding = 'SAME'))\n",
    "\n",
    "model.add(Conv2D(256, [1,1], padding = 'SAME'))\n",
    "model.add(Conv2D(256, [3,3], padding = 'SAME'))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(MaxPool2D(padding = 'SAME'))\n",
    "\n",
    "model.add(Conv2D(512, [1,1], padding = 'SAME'))\n",
    "model.add(Conv2D(512, [3,3], padding = 'SAME',activation = 'relu'))\n",
    "model.add(Conv2D(512, [1,1], padding = 'SAME'))\n",
    "model.add(Conv2D(512, [3,3], padding = 'SAME', activation = 'relu'))\n",
    "model.add(MaxPool2D(padding = 'SAME'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.00, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer =  opt , loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05163dff-fdf7-4652-85c3-3ab1a67d89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names = True)\n",
    "from IPython.display import Image\n",
    "Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612672ba-b43f-478a-8582-e2f31ba6e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = model.fit_generator(generator = train_gen.generate_keras(batch_size), \n",
    "                            steps_per_epoch = train_gen.n_available_samples() // batch_size,\n",
    "                            validation_data = test_gen.generate_keras(batch_size),\n",
    "                            validation_steps = test_gen.n_available_samples() // batch_size, \n",
    "                            epochs = n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad71a24-ed85-4fdb-bfd2-ac6982bb212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(stats.history['acc'], label = 'training acc')\n",
    "plt.plot(stats.history['val_acc'], label = 'validation acc')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(stats.history['loss'], label = 'training loss')\n",
    "plt.plot(stats.history['val_loss'], label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2142f-aa35-441d-91a4-73adc22de31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_gen.generate_keras(test_gen.n_available_samples()).__next__()\n",
    "predictions = model.predict(test_set[0])\n",
    "predictions = np.argmax(predictions, axis = 1)\n",
    "labels = np.argmax(test_set[1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b70066-9b47-4b92-b6a0-e5db34019abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(labels, predictions, target_names = ['none','crackles','wheezes','both']))\n",
    "print(confusion_matrix(labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
